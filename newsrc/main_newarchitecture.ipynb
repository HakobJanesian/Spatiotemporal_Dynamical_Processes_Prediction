{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5663c8db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5663c8db",
    "outputId": "7d8ac497-e64c-4651-d0a8-940525f10cb9"
   },
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326e00db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "326e00db",
    "outputId": "32ce64ff-b91e-4127-fd79-46183bd95faf"
   },
   "outputs": [],
   "source": [
    "#import cv2\n",
    "import torch\n",
    "import imageio\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import Tensor\n",
    "from itertools import compress, cycle\n",
    "from collections import OrderedDict\n",
    "from scipy.interpolate import griddata\n",
    "from IPython.display import Image\n",
    "\n",
    "from utils.utils import *\n",
    "\n",
    "from utils.plotting import Plotter\n",
    "from utils.gl_solver import GLSolver\n",
    "from utils.parameters_init import ParametersInit\n",
    "from utils.random_input_field import RandomInputField\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "EPOCHS = 20_000\n",
    "LR = 1\n",
    "# SEED = 1234\n",
    "\n",
    "# np.random.seed(SEED)\n",
    "# torch.manual_seed(SEED)\n",
    "# torch.cuda.manual_seed(SEED)\n",
    "# torch.cuda.manual_seed_all(SEED)\n",
    "# torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86852a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "Nx=128\n",
    "Ny=128\n",
    "\n",
    "Lx= 50\n",
    "Ly= 50\n",
    "T_end = 1\n",
    "dt = 0.005\n",
    "\n",
    "myubatch_size = 8192\n",
    "myu=16\n",
    "path = f\"main-newarchitecture-N-{Nx}-L-{Lx}-Myu-{myu}-new-approach\"\n",
    "mtlibpath_prefix = path + \"_mtl\"\n",
    "\n",
    "input_to_defect_ratio_sqrt = Nx // myu\n",
    "N_ITERATIONS = int(T_end / dt)\n",
    "A_norm, A_original, mem_rate, myu_original = compute_A_norm(\n",
    "    Nx=Nx, \n",
    "    Ny=Ny, \n",
    "    input_to_defect_ratio=input_to_defect_ratio_sqrt*input_to_defect_ratio_sqrt, \n",
    "    mean=5.4, \n",
    "    std_deviation=0.8, \n",
    "    time_period=25, \n",
    "    Lx=Lx, \n",
    "    Ly=Ly, \n",
    "    dt=dt, \n",
    "    T_End=T_end, \n",
    "    parallel_runs=1, \n",
    "    input_scale=0.75, \n",
    "    mem_coef=1, \n",
    "    time_period_parameter=50, \n",
    "    _mean=5.4, \n",
    "    std_deviation_run_computation=1,\n",
    "    input_myu=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1D-Md_qQdSn-",
   "metadata": {
    "id": "1D-Md_qQdSn-"
   },
   "source": [
    "GETTING HANDS DIRTY WITH THE NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yp-gI3_HdVWJ",
   "metadata": {
    "id": "yp-gI3_HdVWJ"
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, Lx, Nx).flatten()[:, None]\n",
    "y = np.linspace(0, Ly, Ny).flatten()[:, None]\n",
    "t = np.linspace(0, T_end, N_ITERATIONS).flatten()[:, None]\n",
    "\n",
    "Exact = A_original.squeeze(0)\n",
    "\n",
    "X, T, Y = np.meshgrid(x, t, y)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:, None], Y.flatten()[:, None], T.flatten()[:, None]))\n",
    "u_star = Exact.flatten()\n",
    "u_star = np.hstack([u_star.real[:, None],u_star.imag[:, None]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9462a89",
   "metadata": {
    "id": "c9462a89"
   },
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\partial_{t} A &= \\mu A+\\Delta A-|A|^{2} A\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bad1d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self, layers_list, activation_function_list = None):\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        self._depth = len(layers_list) - 1\n",
    "        if activation_function_list is None:\n",
    "            activation_function_list = [torch.nn.Softplus for _ in range(self._depth - 1)]        \n",
    "        \n",
    "        seq = []\n",
    "        for i, activation_function in enumerate(activation_function_list):\n",
    "            seq.append(('layer_%d' % i, torch.nn.Linear(layers_list[i], layers_list[i+1], dtype = torch.float64)))\n",
    "            seq.append(('activation_%d' % i, activation_function()))\n",
    "        \n",
    "        seq.append(('layer_%d' % (self._depth - 1), torch.nn.Linear(layers_list[-2], layers_list[-1], dtype = torch.float64)))\n",
    "        \n",
    "        self._Wtmx = torch.nn.Sequential(OrderedDict(seq))\n",
    "        self.optimizer = torch.optim.Adam( params = self._Wtmx.parameters(), lr=0.01 )    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self._Wtmx(x)\n",
    "    \n",
    "class MShuffle(nn.Module):\n",
    "    def __init__(self, exp_size, n_depth, activation_function_list = None):\n",
    "        nn.Module.__init__(self)\n",
    "        \n",
    "        if activation_function_list is None:\n",
    "            activation_function_list = [torch.nn.Softplus]*exp_size\n",
    "        \n",
    "        seq = []\n",
    "\n",
    "        for nd in range(n_depth):\n",
    "            for n, activation_function in enumerate(activation_function_list):\n",
    "                seq.append(('layer_d_%d_n_%d' % (nd + 1, n + 1), torch.nn.Linear(2**exp_size, 2**(exp_size-1), dtype = torch.float64)))\n",
    "                seq.append(('activation_d_%d_n_%d' % (nd + 1,n + 1), activation_function()))\n",
    "\n",
    "        self._Wtmx = torch.nn.Sequential(OrderedDict(seq))\n",
    "        self.n_depth = n_depth\n",
    "\n",
    "        mask = np.zeros((exp_size,*[2] * exp_size),dtype = bool)\n",
    "        for e in range(exp_size):\n",
    "            exec(f\"mask[{e},{':,'*e+'0'}] = True\")\n",
    "        self.mask = torch.tensor(mask.reshape(exp_size,-1),dtype=bool) \n",
    "\n",
    "    def forward(self,x):\n",
    "        Seq = self._Wtmx.children()\n",
    "        for _ in range(self.n_depth):\n",
    "            for m in self.mask:\n",
    "                x_new = x.clone()\n",
    "                x_new[:,m] = next(Seq)(next(Seq)(x))\n",
    "                x = x_new\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4036c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "class ALLINPUTNET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ALLINPUTNET, self).__init__()\n",
    "        self.encoder = FCN(layers_list = [3,4,16,64,256])\n",
    "        self.decoder = FCN(layers_list = [256,64,16,4,2])\n",
    "        self.shuffler = MShuffle(exp_size = 8, n_depth = 2)\n",
    "        self.optimizer = torch.optim.Adam(params = chain(\n",
    "            self.encoder._Wtmx.parameters(),\n",
    "            self.shuffler._Wtmx.parameters(),\n",
    "            self.decoder._Wtmx.parameters(),\n",
    "            ), lr=0.0001)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        E = self.encoder.forward(x)\n",
    "        S = self.shuffler.forward(E)\n",
    "        return self.decoder.forward(S)\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.eval()\n",
    "        if type(x) is not torch.Tensor:\n",
    "            x = torch.tensor(x, dtype = torch.float64).to(device)\n",
    "        y =  self.forward(x).cpu().detach().numpy()\n",
    "        return y[:,0] + y[:,1]*1j    \n",
    "\n",
    "    def rmsef(self, y, y_pred):\n",
    "        mseloss = torch.sum((y_pred - y)**2, dim = 1)\n",
    "        return torch.mean(torch.sqrt(mseloss))   \n",
    "\n",
    "    def msef(self, y, y_pred):\n",
    "        return torch.mean((y_pred - y)**2)       \n",
    "\n",
    "    def zero_grad(self, set_to_none: bool = False) -> None:\n",
    "        self.encoder._Wtmx.zero_grad()\n",
    "        self.shuffler._Wtmx.zero_grad()\n",
    "        self.decoder._Wtmx.zero_grad()\n",
    "        return super().zero_grad(set_to_none)\n",
    "\n",
    "    def y_proc(y):\n",
    "        MS = y[:,1] * y[:,0]\n",
    "        IR = y[:,1] ** 2 +  y[:,0] ** 2\n",
    "        return torch.vstack((MS,IR)).T\n",
    "        \n",
    "    def fastmsebatchtrain(self, x, y, epochs=100, batch_size = 64):\n",
    "        \n",
    "        x = torch.tensor(x, dtype = torch.float64).to(device)\n",
    "        y = torch.tensor(y, dtype = torch.float64).to(device)\n",
    "        dataloader = DataLoader(dataset = torch.hstack((x,y)), batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        L = []\n",
    "        \n",
    "        pbar = tqdm(total=epochs)\n",
    "        try:\n",
    "            while True:\n",
    "                if pbar.n >= epochs:\n",
    "                    break\n",
    "                for tmp in dataloader:\n",
    "                    (tmpx, tmpy, tmpt, tmpu_real, tmpu_img) = tmp.T\n",
    "                    X = torch.stack((tmpx,tmpy,tmpt)).T\n",
    "                    U = torch.stack((tmpu_real, tmpu_img)).T\n",
    "\n",
    "                    y_pred = self.forward(X)\n",
    "                    loss = self.msef(y_pred,U)\n",
    "                    L.append(loss.cpu().detach().numpy())\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    self.zero_grad()\n",
    "                    self.optimizer.zero_grad()\n",
    "                    # Update the progress bar\n",
    "                    if pbar.n >= epochs:\n",
    "                        break\n",
    "                    pbar.update(1)\n",
    "                        \n",
    "        except Exception as e:\n",
    "            raise Exception(e)\n",
    "        finally:\n",
    "            # Close the progress bar\n",
    "            pbar.close()          \n",
    "        return L\n",
    "    \n",
    "    def fastrmsebatchtrain(self, x, y, epochs=100, batch_size = 64):\n",
    "        \n",
    "        x = torch.tensor(x, dtype = torch.float64).to(device)\n",
    "        y = torch.tensor(y, dtype = torch.float64).to(device)\n",
    "        dataloader = DataLoader(dataset = torch.hstack((x,y)), batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        L = []\n",
    "        \n",
    "        pbar = tqdm(total=epochs)\n",
    "        try:\n",
    "            while pbar.n < epochs:\n",
    "                for tmp in dataloader:\n",
    "                    (tmpx, tmpy, tmpt, tmpu_real, tmpu_img) = tmp.T\n",
    "                    X = torch.stack((tmpx,tmpy,tmpt)).T\n",
    "                    U = torch.stack((tmpu_real, tmpu_img)).T\n",
    "\n",
    "                    y_pred = self.forward(X)\n",
    "                    loss = self.rmsef(y_pred,U)\n",
    "                    L.append(loss.cpu().detach().numpy())\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    self.zero_grad()\n",
    "                    self.optimizer.zero_grad()\n",
    "                    # Update the progress bar\n",
    "                    if pbar.n >= epochs:\n",
    "                        break\n",
    "                    pbar.update(1)\n",
    "                        \n",
    "        except Exception as e:\n",
    "            raise Exception(e)\n",
    "        finally:\n",
    "            # Close the progress bar\n",
    "            pbar.close()          \n",
    "        return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALLINPUTPINN(ALLINPUTNET):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super(ALLINPUTPINN, self).__init__(*args,**kwargs)\n",
    "#         myu = torch.randn(4, 2, dtype=torch.float64).to(device)\n",
    "#         myu = nn.Parameter(myu)\n",
    "#         self._Wtmx.register_parameter('myu', myu)\n",
    "#         self.myuparam = myu\n",
    "#         myu = transform_and_stack(myu, 4, 200).to(device).clone().requires_grad_(True)\n",
    "#         self.myu = myu.view(200, 4, 4)\n",
    "        self.myureset()\n",
    "    \n",
    "    def myureset(self):\n",
    "        myu = torch.randn(mem_rate, Nx//input_to_defect_ratio_sqrt, Ny//input_to_defect_ratio_sqrt, dtype=torch.float64).to(device)\n",
    "        myu = nn.Parameter(myu)\n",
    "        self.myuparam = myu\n",
    "        \n",
    "    @property\n",
    "    def myu(self):\n",
    "        myu = F.interpolate(self.myuparam.unsqueeze(0), scale_factor=input_to_defect_ratio_sqrt, mode='nearest').squeeze()\n",
    "        return myu\n",
    "    \n",
    "    def loaddata_precalculate(self,x):\n",
    "        myuloss = MYULOSS(*tuple(x.T),self)\n",
    "        myuloss.calculate_f_withoutmyu()\n",
    "        self.myuloss = myuloss\n",
    "    \n",
    "    def fmsef(self, myu):\n",
    "        return self.myuloss.fmse(myu)\n",
    "    \n",
    "    def fmse(self):\n",
    "        return self.fmsef(self.myu)\n",
    "    \n",
    "    def myutrain(self, epochs=100, lr = 0.01):\n",
    "        \n",
    "        myuoptimizer = torch.optim.Adam( params = [self.myuparam], lr=lr ) \n",
    "        myuoptimizer.zero_grad()\n",
    "\n",
    "        for _ in tqdm(range(epochs)):\n",
    "            self.fmse().backward(retain_graph=True)\n",
    "            myuoptimizer.step()\n",
    "            myuoptimizer.zero_grad()\n",
    "        \n",
    "        FMSE = self.myuloss.FMSE\n",
    "        self.myuloss.clear()\n",
    "        return FMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MYULOSS:\n",
    "  def __init__(self, x, y, t, net, verbose = 0):\n",
    "      self.msef = nn.MSELoss()\n",
    "      self.FMSE = []\n",
    "      self.x = x\n",
    "      self.y = y\n",
    "      self.t = t\n",
    "      self.net = net\n",
    "        \n",
    "  def plot(self, title= 'MYU training'):\n",
    "    plt.plot(self.FMSE)\n",
    "    plt.yscale('log')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('FMSE')\n",
    "    self.clear()\n",
    "    \n",
    "  def clear(self):\n",
    "    self.FMSE = []\n",
    "    \n",
    "  def fmse(self, myu):\n",
    "    f_loss = torch.mean(torch.abs(self.net_f(myu)) ** 2)\n",
    "    self.FMSE.append(f_loss.cpu().detach().numpy())\n",
    "    return f_loss\n",
    "  \n",
    "  def net_f(self, myu, verbose = 0):\n",
    "        return self.f_withoutmyu - myu*self.u \n",
    "    \n",
    "  def calculate_f_withoutmyu(self):\n",
    "        x,y,t = self.x, self.y, self.t\n",
    "        \n",
    "        u, u_t,u_xx,u_yy = MYULOSS.pref(x,y,t,net)\n",
    "        \n",
    "        self.u = u.cpu().detach()\n",
    "            \n",
    "        f_withoutmyu = u_t - (u_xx + u_yy) + torch.pow(torch.abs(u), 2)*u #- myu*u\n",
    "        self.f_withoutmyu = f_withoutmyu.cpu().detach()\n",
    "        free_memory(u_t, u_xx, u_yy, u, f_withoutmyu)\n",
    "\n",
    "    \n",
    "  def f_withoutmyu(x,y,t,ru,iu):\n",
    "        (ru_t, ru_x, ru_y) = torch.autograd.grad(ru, (t, x, y), grad_outputs=torch.ones_like(ru), create_graph=True, retain_graph=True)\n",
    "        (iu_t, iu_x, iu_y) = torch.autograd.grad(iu, (t, x, y), grad_outputs=torch.ones_like(iu), create_graph=True, retain_graph=True)\n",
    "\n",
    "        (ru_xx,) = torch.autograd.grad(ru_x, (x), grad_outputs=torch.ones_like(ru_x), create_graph=True)\n",
    "        (iu_xx,) = torch.autograd.grad(iu_x, (x), grad_outputs=torch.ones_like(iu_x), create_graph=True)\n",
    "\n",
    "        (ru_yy,) = torch.autograd.grad(ru_y, (y), grad_outputs=torch.ones_like(ru_y), create_graph=True)\n",
    "        (iu_yy,) = torch.autograd.grad(iu_y, (y), grad_outputs=torch.ones_like(iu_y), create_graph=True)\n",
    "\n",
    "        u =( ru + iu * 1j)\n",
    "        u_t = (ru_t + iu_t * 1j)\n",
    "        u_xx =( ru_xx + iu_xx *1j)\n",
    "        u_yy = (ru_yy + iu_yy *1j)\n",
    "        \n",
    "        return u, u_t,u_xx,u_yy\n",
    "    \n",
    "  def pref(x,y,t, net, batch_size = myubatch_size):\n",
    "    dataloader = DataLoader(dataset = X_star, batch_size = batch_size, shuffle=False)\n",
    "    cache = {\n",
    "        'u':[],\n",
    "        'u_t':[],\n",
    "        'u_xx':[],\n",
    "        'u_yy':[],\n",
    "    }\n",
    "    for tmp in tqdm(dataloader):\n",
    "        x,y,t = torch.tensor(tmp.T, dtype = torch.float64, requires_grad=True).to(device)\n",
    "        ru,iu = net.forward(torch.stack((x,y,t)).T).T\n",
    "        u, u_t,u_xx,u_yy = MYULOSS.f_withoutmyu(x,y,t,ru,iu)\n",
    "        cache['u'].append(u.cpu().detach())\n",
    "        cache['u_t'].append(u_t.cpu().detach())\n",
    "        cache['u_xx'].append(u_xx.cpu().detach())\n",
    "        cache['u_yy'].append(u_yy.cpu().detach())\n",
    "        \n",
    "    return  torch.cat(cache['u']).view(mem_rate, Nx, Ny), \\\n",
    "            torch.cat(cache['u_t']).view(mem_rate, Nx, Ny),\\\n",
    "            torch.cat(cache['u_xx']).view(mem_rate, Nx, Ny),\\\n",
    "            torch.cat(cache['u_yy']).view(mem_rate, Nx, Ny)\n",
    "\n",
    "      \n",
    "def free_memory(*variables):\n",
    "    del variables\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315c3bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "device = 'cpu'\n",
    "net = ALLINPUTPINN().to(device)\n",
    "u_star_proc = ALLINPUTPINN.y_proc(torch.tensor(u_star, dtype = torch.float64).to(device))\n",
    "L1 = net.fastrmsebatchtrain(x = X_star, y = u_star_proc, epochs = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0311c5c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(L1)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Custom Loss')\n",
    "plt.title('Training of the AllInputNet \\n lr=0.01')\n",
    "plt.savefig(f'{mtlibpath_prefix}_allinputnet001.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.optimizer.param_groups[0]['lr'] = 0.001\n",
    "#L2 = net.fastbatchtrain(x = X_star, y_proc = u_star_proc, epochs = 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea994c61",
   "metadata": {},
   "source": [
    "## calculating myus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c8864",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = net.to(device)\n",
    "net.loaddata_precalculate(X_star)\n",
    "net.myureset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e31092",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = net.to(device)\n",
    "net.myureset()\n",
    "\n",
    "i = 0\n",
    "for lr in [10, 3, 1, 0.3]:\n",
    "    L = net.myutrain(lr=lr, epochs=10)\n",
    "    l = net.fmse().cpu().detach().numpy()\n",
    "    L += [l]\n",
    "    net.myuloss.clear()\n",
    " \n",
    "    plt.plot(range(i,i+len(L)), L, label=f'lr={lr}')\n",
    "    i+=len(L)-1\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('FMSE')\n",
    "plt.title('MYU Training')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{mtlibpath_prefix}_myutraining.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b2c683",
   "metadata": {},
   "source": [
    "## Visualizing and saving plot gifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc353247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(index, u_im_real, o_im_real, phase,  title):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Display the u_pred image\n",
    "    im1 = axs[0].imshow(u_im_real[index])\n",
    "    axs[0].set_title(title + \" (u_pred) without normalization\" + f\" - Frame: {index}\")\n",
    "    axs[0].title.set_position([.5, 1.05])\n",
    "    \n",
    "    # Display the original image\n",
    "    im2 = axs[1].imshow(o_im_real[index])\n",
    "    axs[1].set_title(title + \" (original) without normalization\" + f\" - Frame: {index}\")\n",
    "    axs[1].title.set_position([.5, 1.05])\n",
    "    \n",
    "    # Display the difference image\n",
    "    im3 = axs[2].imshow(np.abs(u_im_real[index] - o_im_real[index]))\n",
    "    axs[2].set_title(title + \" (difference) without normalization\" + f\" - Frame: {index}\")\n",
    "    axs[2].title.set_position([.5, 1.05])\n",
    "    \n",
    "    # Add colorbars\n",
    "    fig.colorbar(im1, ax=axs[0], fraction=0.046, pad=0.04)\n",
    "    fig.colorbar(im2, ax=axs[1], fraction=0.046, pad=0.04)\n",
    "    fig.colorbar(im3, ax=axs[2], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Draw the figure and store the image\n",
    "    fig.canvas.draw()\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e3095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subframe(fig, ax, m, title):\n",
    "    \n",
    "    im = ax.imshow(m)\n",
    "    ax.title.set_position([.5, 1.05])\n",
    "    im = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "def process_frame(M, titles):\n",
    "    figsize = (M.shape[0], M.shape[1])\n",
    "    fig, axs = plt.subplots(*figsize, figsize=(18, 6))\n",
    "    \n",
    "    # Draw\n",
    "    for i in range(figsize[0]):\n",
    "        for j in range(figsize[1]):\n",
    "            ax = axs[i][j]\n",
    "            process_subframe(fig,axs[i][j], M[i][j],titles[i][j])\n",
    "            \n",
    "    # Draw the figure and store the image\n",
    "    fig.canvas.draw()\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return image   \n",
    "\n",
    "def create_video(M,titles, videotitle, save=True, fps=30):\n",
    "    \n",
    "    \n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "#    images = Parallel(n_jobs=num_cores)(delayed(process_frame)((m,titles) for m in tqdm(M)))\n",
    "    images = [process_frame(m,titles) for m in M]\n",
    "    if save:\n",
    "        images_to_video(images, videotitle, fps=30)\n",
    "        print(\"Video successfully saved at\", videotitle)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def create_video(M,titles, videotitle, save=True, fps=30):\n",
    "    \n",
    "    \n",
    "    images = [process_frame(m,titles) for m in M]\n",
    "    #Parallel(n_jobs=num_cores)(delayed(process_frame)(m, titles) for m in tqdm(M))\n",
    "    if save:\n",
    "        # Convert images to 8-bit color for video\n",
    "        images = [cv2.cvtColor(img, cv2.COLOR_RGB2BGR) for img in images]\n",
    "        height, width, _ = images[0].shape\n",
    "        video = cv2.VideoWriter(videotitle, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "        for img in images:\n",
    "            video.write(img)\n",
    "        video.release()\n",
    "        print(\"Video successfully saved at\", videotitle)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58e04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import cv2\n",
    "import torch\n",
    "import imageio\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import List, Optional\n",
    "from joblib import Parallel, delayed\n",
    "from torch.nn.parameter import Parameter\n",
    "from IPython.display import display, Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d820d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_sq = lambda a: np.real(a)**2 + np.imag(a)**2\n",
    "phase = lambda a: np.arcsin(np.real(a)/np.sqrt(np.real(a)**2+np.imag(a)**2))\n",
    "real_imag = lambda a: np.real(a)*np.imag(a)\n",
    "real = lambda a: np.real(a)\n",
    "imag = lambda a: np.imag(a)\n",
    "\n",
    "funlist_name = [\"module_sq\", \"phase\",\"real_imag\",\"real\",\"imag\"]\n",
    "funlist = [module_sq, phase, real_imag, real, imag]\n",
    "\n",
    "myu = myu_original[0]\n",
    "myupred = net.myu.cpu().detach().numpy()\n",
    "\n",
    "A_pred = net.predict(X_star).reshape(A_original[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9c59c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATenzor = np.array([np.stack([np.stack([fun(A) for fun in funlist]),\n",
    "                    np.stack([fun(Ap) for fun in funlist])]) for A, Ap in zip(A_original[0], A_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f95739",
   "metadata": {},
   "outputs": [],
   "source": [
    "MTenzor = np.array([np.array([m,mp]) for m, mp in zip(myu,myupred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4af55d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMTenzor = np.concatenate((MTenzor[:, :, np.newaxis, :, :], ATenzor), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2d619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_video(AMTenzor, titles=[['myu'] + funlist_name]*2, videotitle = path+'.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216de9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af394405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0e1ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c54f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f1dc17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3964479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669c674b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92008834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
